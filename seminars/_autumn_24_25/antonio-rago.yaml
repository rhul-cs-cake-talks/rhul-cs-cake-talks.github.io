---
topic: Machine Learning
type: Technical
title: >
  A Little of That Human Touch: Achieving Human-Centric Explainable AI via Argumentation
speaker: Antonio Rago
institution: Imperial College London
webpage:  https://www.imperial.ac.uk/people/a.rago
date: 2024-11-20 11:00
venue: BOURNE-LT2
link: https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZDdiNDU5OTUtOTY1Ni00Y2ZlLWEyYjEtYTA2ZDM4MGNhZGI0%40thread.v2/0?context=%7b%22Tid%22%3a%222efd699a-1922-4e69-b601-108008d28a2e%22%2c%22Oid%22%3a%229c6a898b-86f6-4344-8f36-27129ffe3748%22%7d
recording: 
bio: >
  Antonio is a Research Associate in the Department of Computing at Imperial College London, where he also completed a PhD titled “Gradual Evaluation in Argumentation Frameworks: Methods, Properties and Applications” under the supervision of Prof. Francesca Toni. His main research interests lie in the deployment of argumentative technologies to applications, particularly in explainable AI, e.g. for explaining the outputs of neural networks, recommender systems or Bayesian classifiers, but also in other settings such as e- engineering, medicine, democracy and judgemental forecasting.

abstract: >
  As data-driven AI models achieve unprecedented feats across previously unthinkable tasks, the diminishing levels of interpretability of their increasingly complex architectures can often be sidelined in place of performance. If we are to comprehend and trust these AI models as they advance, it is clear that symbolic methods, given their unparalleled strengths in knowledge representation and reasoning, can play an important role in explaining AI models. In this talk, I discuss some of the ways in which one branch of such methods, computational argumentation, given its human-like nature, can be used to tackle this problem. I first outline a general paradigm for this area of explainable AI, before detailing a prominent methodology therein which we have pioneered. I then illustrate how this approach has been put into practice with diverse AI models and types of explanations, before looking ahead to challenges, future work and the outlook in this field.


---
