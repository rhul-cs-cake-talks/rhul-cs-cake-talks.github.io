---
topic: Machine Learning
type: Technical
title: Designing Efficient and Trustworthy AI Hardware.
speaker: Bipin Rajendran
institution: King's College London
webpage: https://sites.google.com/site/rajendranbipin/
date: 2024-03-08 14:00
venue: Founder West 101
link: https://teams.microsoft.com/l/meetup-join/19%3ameeting_YWUwNGJiODYtODg3Zi00OTJhLWE2YmQtZDU2YWU2ODUzNjdh%40thread.v2/0?context=%7b%22Tid%22%3a%222efd699a-1922-4e69-b601-108008d28a2e%22%2c%22Oid%22%3a%22a039aadc-3c03-47d9-9b54-085490a7ce53%22%7d
recording: https://rhul-my.sharepoint.com/:v:/g/personal/anand_subramoney_rhul_ac_uk/EWdFTpxGgvhFie4UBLy06oUBnuJMU3-uicwmBf7YQ5-psg?e=hN9RyR
bio: >
  Bipin Rajendran is a Professor of Intelligent Computing Systems and EPSRC Fellow at King's College London (KCL). He received a B. Tech degree from I.I.T. Kharagpur in 2000, and MS and PhD degrees in Electrical Engineering from Stanford University in 2003 and 2006, respectively. He was a Master Inventor and Research Staff Member at IBM T. J. Watson Research Center in New York from 2006-'12 and has held faculty positions in India and the US. His research focuses on building algorithms, devices, and systems for brain-inspired computing. He has co-authored over 95 papers in peer-reviewed journals and conferences, one monograph, one edited book, and 59 issued U.S. patents. He is a recipient of the IBM Faculty Award (2019), IBM Research Division Award (2012), and IBM Technical Accomplishment Award (2010). He was elected a senior member of the US National Academy of Inventors in 2019.
abstract: >
  The complexity of AI models have been increasing exponentially, leading to exploding energy costs for training and inference. Furthermore, they often provide unreliable results and predictions, as they are unable to account for uncertainty in models or data.
  In this talk, I will discuss our recent results on designing efficient and trustworthy AI hardware based on nanoscale memristive devices. I will discuss how hardware-aware training of AI models can be used to mitigate the effect of device noise to implement in-memory computing architectures and achieve over 100-fold improvement in inference efficiency compared to CMOS designs. I will also describe how we can leverage nanoscale device stochasticity to implement Bayesian AI models that are able to provide quantifiable metrics of uncertainty associated with their decisions.

---
